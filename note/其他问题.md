



#### 自我介绍

我叫王雨鹏，家在河北保定，本科就读于河南理工大学。现在是天津工业大学研二的学生，专业计算机技术，26年毕业。

在技术方面的话，自己学习了一些c++相关的技术栈，比如说，c++的面向对象编程，STL的常用容器，以及c++11的一些常用新特性（智能指针等）。

对Linux系统编程也有一些了解，比如多线程编程，网络编程，IO复用这些。

计算机基础方面，了解一些操作系统，计算机网络的基础知识，然后数据库的MYSQL都有一些了解。



自己在学习过程中也，为了深化理解做了几个项目，一个是Linux下的web服务器，实现了一个基于HTTP协议的简单的服务器，另外一个是实现了一个线程安全的高并发缓存系统。

大概就是这些情况。



#### 职业规划  未来规划





#### 优点











## webserver项目：

这个项⽬是我在学习计算机⽹络和Linux socket编程过程中独⽴开发的基于HTTP协议的轻量级Web服务器，

事件处理模型reactor和proactor均实现。

IO处理使⽤了⾮阻塞SOCKET和epoll（LT + ET均实现），支持对用户访问的并发处理。

支持客户端访问服务器的图片，视频、音频资源，支持请求中英文文件名。通过将用户账户信息存入数据库对用户登录进行校验。

然后做了**线程池**+数据库连接池+**日志系统**+**定时器**处理非活动连接的优化



#### 项目流程

**首先是服务器的一个参数初始化操作。**

通过构造WebServer这个对象传递参数进行服务器相关参数的设定，主要参数有设置Epoll触发模式、设置日志系统的开启、以及异步开关、设置线程池的线程数量、设置事件处理模型。

**然后是通过设定的参数对服务器的各个模块进行初始化。主要有日志、线程池、数据库连接池、IO复用、HTTP对象、缓冲区、阻塞队列等模块。**

日志模块的初始化是先建立一个日志文件，通过一个变量按照天数去划分不同的日志文件。线程池采用RAII手法，在构造时创建线程，析构时唤醒所有睡眠的线程使其退出循环。数据库连接池主要是初始化一系列数据库连接并使用list容器进行管理。IO复用是对epoll函数调用的一个封装。HTTP对象主要设置参数的初始化以及文件存放的相关路径。缓冲区和阻塞队列主要完成指定大小的参数设定。



**服务器各个模块初始化完成之后就是主线程里IO复用监听事件的循环。**

监听事件有新连接到达、读事件和写事件和异常事件。根据不同的事件进行一个任务处理。



当新连接到达的时候，通过**调用accept取出新连接**（ET模式下需要循环操作），将新连接的文件描述符用来**初始化HTTP连接**（套接字地址和文件描述符绑定到一个HTTP对象），**完成绑定定时器的初始化，同时添加监听读事件**，设置其文件描述符为非阻塞。

当有异常事件发生的时候，关闭该连接同时移除监听事件和定时器。

当触发读事件的时候，调整定时器的定时时间，将读任务放入线程池的任务队列当中去。这个时候线程池对象里的多个线程，处于一个睡眠或者竞争任务并执行的过程，任务加入到任务队列当中去时会发送一个唤醒信号，如果有睡眠的线程则会被唤醒，进入循环里探测任务队列是否为空，取出任务并执行或者队列为空继续睡眠。

线程执行读任务函数主要是**完成一个非阻塞读取调用直到读完**，将数据缓存在用户缓冲区中，**接着执行一个消息解析的操作**，根据HTTP解析是否成功的判断来决定重新注册写事件还是读事件。如果解析失败那么重新注册读事件等待下次读取更多数据直到一个完整的HTTP请求。如果是解析成功的话就制作响应报文并且注册写事件，等待内核缓冲区可写触发事件时，将其写入内核缓冲区。

这部分的重点是逻辑处理的过程，也就是HTTP解析和HTTP报文的制作。

解析采用的是状态机和正则表达式，每次都读取以\r\n结尾的一段字符串，通过状态机来判定获取的字符串是属于HTTP请求的哪一部分，再跳转到相应的函数进行解析，如果读取的字符串没有以\r\n结尾则认为此次数据获取不完整，返回解析失败重新注册读事件。如果解析完成之后则根据解析过程中保存的相应信息，制作响应报文，通过集中写将资源文件和响应报文分别发送回客户端。





#### 项目难点：

1. 编写主从状态机对HTTP报文进行解析和响应的过程。
2. 整个框架的搭建（IO处理  事件处理），以及整个过程中对客户端的请求的流程的梳理。







### 定时器

#### 定时器处理非活动连接

`非活跃`，是指**客户端（这里是浏览器）与服务器端建立连接后，长时间不交换数据**，一直占用服务器端的文件描述符，导致连接资源的浪费。

`定时事件`，**是指固定一段时间之后触发某段代码，由该段代码处理一个事件**，如从内核事件表删除事件，并关闭文件描述符，释放连接资源。

`定时器`，是指**利用结构体或其他形式，将多种定时事件进行封装起来**。具体的，这里只涉及一种定时事件，即定期检测非活跃连接，这里将该定时事件与连接资源封装为一个结构体定时器。

`定时器容器`，是指使用**某种容器类数据结构，将上述多个定时器组合起来**，便于对定时事件统一管理。具体的，项目中使用升序链表将所有定时器串联组织起来。

**具体的，利用`alarm`函数周期性地触发`SIGALRM`信号，信号处理函数利用管道通知主循环，主循环接收到该信号后对升序链表上所有定时器进行处理，若该段时间内没有交换数据，则将该连接关闭，释放所占用的资源。**



#### 信号通知逻辑

- 创建管道，其中管道写端写入信号值，管道读端通过I/O复用系统监测读事件

- 设置信号处理函数SIGALRM（时间到了触发）和SIGTERM（kill会触发，Ctrl+C）
- 利用I/O复用系统监听管道读端文件描述符的可读事件
- 信号处理函数会往管道写端写入信号值，主循环根据接收到的信号值执行目标信号对应的处理流程



#### 常用的定时器结构和他们的差异

基于**升序链表**实现的定时器结构按照超时时间作为升序做排序，由于链表的有序性以及不支持随机访问的特性，插入的时间复杂度是O（n），删除的事件复杂度低O(1)，每次扫描的时间复杂度是O(n)



**时间轮**利用哈希思想，将相差整个计时周期整数倍的定时器散列到同一个时间槽中，减少单个链表上的定时器数量避免过多的顺序遍历操作。时间轮通过提高时间槽的数量来提高查找效率【使每个时间槽里的链表长度尽可能短】，通过减少计时间隔来提高定时器的精度【使定时时间尽可能准确】。添加删除O(1)，扫描O(n)，但实际上



基于最小堆的定时器，每次取堆头都是最短的超时时间，可以将所有定时器中超时时间最小的一个定时器的超时时间作为扫描间隔，这样，一旦信号处理函数被调用，超时时间最小的定时器必然到期。然后再从剩余的定时器中取出超时时间最小的一个，作为下一次的时间间隔，如此往复，实现较为精确的定时。插入删除O(logn)，查找O(1)

### 日志系统：

#### 日志系统概述

本项目中，使用单例模式创建日志系统，对服务器运行状态、错误信息和访问数据进行记录。该系统可以实现按天分文件，超行分文件功能。可以根据实际情况分别使用同步和异步写入两种方式。

其中异步写入方式，将生产者-消费者模型封装为阻塞队列，创建一个写线程，工作线程将要写的内容push进队列，写线程从队列中取出内容，写入日志文件。



异步日志：

将日志内容先存入日志队列，由专门的线程从队列中取出内容，写入文件。

同步日志：

主线程等日志写完以后，才能执行后续的操作。单条日志比较大的时候，会阻塞整个处理流程。



#### 为什么要异步，和同步的区别是什么？

因为同步日志的，**日志写入函数与工作线程串行执行，由于涉及到I/O操作**，在单条日志比较大的时候，**同步模式会阻塞整个处理流程**，**服务器所能处理的并发能力将有所下降，**尤其是在峰值的时候，写日志可能成为系统的瓶颈。

而异步日志采用生产者-消费者模型，工作线程将所写的日志内容先存阻塞队列，写线程从阻塞队列中取出内容，写入日志。并发能力比较高

阻塞队列：Deque（里面放的是字符串，要写的日志信息）、互斥锁、条件变量（生产者消费者）

阻塞体现在生产者消费者模型上，当队列里没有日志可写，就阻塞等待，有日志，就唤醒线程进行写日志



#### 日志系统记录的内容及作用？

在开发其他模块的时候主要用来记录模块的信息，通过日志判断模块功能是否正常。

在服务器运行期间主要记录**服务器设定的参数、请求报文，响应报文，新客户的建立与断开、异常事件的发生**（并发数量达到上限、套接字初始化失败等，系统调用调用失败）。便于对服务器运行过程中一些不明情况的分析。

#### 日志系统的实现需要考虑什么？

线程安全和效率问题

首先是线程安全方面，日志系统需要记录多个连接运行的情况，也就是说日志系统被多个线程拥有，这个时候需要考虑线程安全的问题，通过内部关键操作（涉及临界区资源的部分）进行加锁，实现每个线程对日志对象的访问不会产生冲突，避免日志写入的混乱。

  

### HTTP

**你这个保存状态了吗？如果要保存，你会怎么做？**









#### 日志系统单例模式是怎样实现的

日志系统采用了 C++11 之后支持的**线程安全的懒汉式单例模式**，在 `get_instance()` 函数中通过定义**静态局部变量 `static Log instance` 实现单例对象的创建**。由于 C++11 标准保证了静态局部变量初始化的线程安全性，因此**无需额外加锁**，从而实现了高效且安全的懒加载单例。同时，代码中将**拷贝构造函数，赋值运算符显式删除**，并将**构造函数析构函数设为私有**，进一步防止了对象被复制或在类外被销毁，确保了日志系统全局唯一的实例性和生命周期的受控管理。



#### 如果服务器在运⾏的过程中，实际存储的⽂件被其他⽤户修改了，会发⽣什么？以及应该怎么做

**内存中的日志还没写入磁盘，会丢失**

**日志文件可能损坏**

**日志信息不完整，难以排查崩溃原因**



解决：

及时刷新

异常时强制刷新

将日志发送给日志服务，由日志服务进行异步处理、落盘、写入等。



















### 项目介绍

#### 数据的流向

这个Web服务器的请求处理流程如下：

1. 客户端连接阶段：
   - 客户端通过TCP连接到服务器(webserver.cpp中的eventListen)
   - 服务器accept连接并创建定时器(webserver.cpp中的timer函数)
   - 初始化http_conn对象关联该连接
2. 请求接收阶段：
   - epoll检测到可读事件(webserver.cpp中的eventLoop)
   - 根据触发模式(LT/ET)读取数据(http_conn::read_once)
   - 解析HTTP请求(process_read)：
     - 解析请求行(parse_request_line)
     - 解析请求头(parse_headers)
     - 解析请求体(parse_content)
3. 请求处理阶段：
   - 根据URL路径处理请求(do_request)：
     - 静态文件：映射文件到内存(mmap)
     - 动态请求：处理登录/注册等CGI请求
   - 查询数据库验证用户信息(initmysql_result)
4. 响应生成阶段：
   - 生成HTTP响应头(add_status_line/add_headers)
   - 准备响应内容：
     - 静态文件：使用内存映射文件
     - 动态内容：生成HTML响应
   - 通过writev高效发送响应(write函数)
5. 连接管理阶段：
   - 根据Connection头决定是否保持连接
   - 更新定时器(adjust_timer)或关闭连接(deal_timer)





#### reactor模式   proactor模式

Reactor模式：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程（逻辑单元），将socket可读可写事件放入请求队列，交给工作线程处理。（事件分发器 事件处理器 时间循环）

Proactor模式：Proactor模式是一种基于异步I/O操作的设计模式。将所有的I/O操作都交给内核来处理（进行读、写），并在I/O操作完成后通知应用程序。工作线程仅负责处理逻辑（对报文的解析和响应），（主线程 工作线程 异步 IO 机制）



#### 项目中遇到的困难 怎么解决的

1.⼀⽅⾯是对不同的技术理解不够深刻   找教程  去阅读别人的一些文章

2 项目遇到的bug  	通过日志  通过gdb  问ai。去网上看有没有类似的bug，向同学或网站上求助



#### 遇到的bug：

大文件传输：

iovec 结构体数组，存放的是有多少个缓冲区的数据需要发送，存放起始地址以及长度

调用writeev后，没有更新iov_len和iov_base导致还按照以前的长度和base进行传输，导致错误。

解决：调用一次writev后，根据已经写入的数据的大小，调整iov_len和iov_base位置，



请求中文文件名：URL只能放askii

#### 很多⼈的简历上都会有这个项⽬，为什么你还要选择？

（项⽬是在学习计⽹的过程中逐步搭建 的，这个项⽬综合性⽐较强，从中既能学习Linux环境下的⼀些系统调⽤，也能熟悉⽹络编程和⼀些⽹络框 架，其中也根据⾃⼰的理解加⼊了⼀些性能调优的⼿段）讲⼀下你刚才讲的那些性能调优的⼿段？（从程序本 身的优化和系统参数的优化两⽅⾯去讲）



### 用到了什么设计模式

















### 线程池

#### 你的线程池工作线程处理完一个任务后的状态是什么？

  这里要分为两种情况考虑
 1.当处理完任务后如果请求队列为空时，则这个线程重新回到阻塞等待的状态。
 2.当处理完任务后如果请求队列不为空时，那么这个线程将处于与其他线程竞争资源的状态，谁能获得锁谁就获得了处理事件的资格。

#### 讲一下你项目中线程池的作用？具体是怎么实现的？

在我的项目中，线程池的主要作用是**提高服务器处理并发请求的效率**，**避免频繁创建和销毁线程**所带来的资源开销，同时支持高并发的任务处理能力。

具体实现方面，线程池通过在构造函数中指定线程数量和最大请求数，创建了一组工作线程，这些线程在主线程的管理下持续等待并处理任务。在请求到来时，主线程将请求任务放入队列中，并通过信号量和互斥锁来确保线程安全。工作线程从任务队列中取出任务并执行，使用了 Reactor 或 Proactor 模式来处理 I/O 和业务逻辑的分离。



### 数据库连接池

#### 数据库连接池怎么设计的

**这个数据库连接池通过单例 + RAII + 信号量 + 互斥锁，实现了高效、线程安全、自动释放的数据库连接管理机制。**

这个数据库连接池通过单例模式保证全局唯一实例，使用互斥锁和信号量实现多线程下的线程安全管理，预先创建多个数据库连接存储在连接列表中，避免频繁建立和销毁连接带来的性能损耗。通过 `GetConnection` 和 `ReleaseConnection` 管理连接的获取与归还，配合 RAII 机制实现自动释放连接，确保资源不泄漏，提升系统性能和稳定性。

#### 连接中断会不会检测到



#### 链接有没有超时时间，用了多久会自动释放掉





### 并发性问题

#### 如果同时1000个客户端请求数据，但是线程不够，怎么能及时处理每一个响应

⾸先我项⽬中使⽤了I/O多路复⽤技术，每个线程中管理⼀定数量的连接，只有线程池中的连接有请求，epoll就会 返回请求的连接列表，管理该连接的线程获取活动列表，然后依次处理各个连接的请求。如果该线程没有任务，就 会等待主reactor分配任务。这样就能达到服务器⾼并发的要求，同⼀时刻，每个线程都在处理⾃⼰所管理连接的 请求。  



### IO复用









### 缓存项目



#### arc缓存

1. 客户端访问数据时，先查缓存是否命中

- 从缓存中查找某个 key 对应的数据。
- 如果 **命中缓存**，就从主缓存（LRU 或 LFU）返回。
- 如果 **未命中缓存**，称为**缓存穿透**，需要从磁盘加载数据。

------

**2. 如果未命中缓存 → 缓存穿透**

- 从磁盘中读取数据。
- 插入到 LRU 缓存的链表尾部（这里用的是尾插，也可以是头插，效果相同）。
- 如果 LRU 缓存已满：
  - 淘汰 LRU 链表的头部元素。
  - 把这个被淘汰的 key 加入到 LRU 的 ghost list。
  - 如果 ghost list 也满了，FIFO 淘汰其头部元素。

------

**3. 如果命中缓存：**

3.1 命中在 LRU 中，**但 LFU 中没有：**

- 判断这个数据的访问次数是否超过 `transformTime_`（例如设置为 3）。
- 如果超过：
  - 把它也插入到 LFU 中，说明它不光是最近被访问，还是频繁访问的数据。
- 这样数据会同时存在于 LRU 和 LFU，方便后续提频率。

3.2 命中在 LFU 中：

- 增加其访问频次（计数器 +1）。
- 将它重新插入 LFU 链表合适位置（移动到更靠“尾”的地方）。
- 这样：
  - 高频数据会“留在” LFU；
  - 不常访问的数据自然会“向头部移动”，最终被淘汰。

------

**4. Ghost list 的作用（LRU ghost 和 LFU ghost）**

4.1 如果未命中，但 key 在 **LRU ghost list** 中：

- 表示这是“最近刚刚被淘汰”的数据 —— 即：访问模式更倾向于“最近性”（LRU）。
- 说明 LRU 空间太小了 → 应该调整：
  - 增大 LRU 的空间（partition 右移一格）。
  - 减少 LFU 空间。
- 然后将 key 从 ghost list 移除，并将数据插入 LRU 缓存尾部。

4.2 如果未命中，但 key 在 **LFU ghost list** 中：

- 表示访问模式偏向“频繁性”（LFU）。
- 说明 LFU 空间太小了 → 应该调整：
  - 增大 LFU 的空间（partition 左移一格）。
  - 减少 LRU 空间。
- 同样将 ghost list 中该 key 移除，将数据加入 LRU 缓存尾部。

------

🧾 总结一句话：

> 这段话描述了一个自适应缓存系统如何根据访问命中情况（在缓存、LRU ghost、LFU ghost）智能调整 LRU 和 LFU 的空间比例，以同时兼顾“最近使用”和“最常使用”的访问模式。







https://blog.csdn.net/sbsbsb666666/article/details/130198264?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-3-130198264-blog-142534135.235%5Ev43%5Epc_blog_bottom_relevance_base6&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-3-130198264-blog-142534135.235%5Ev43%5Epc_blog_bottom_relevance_base6

#### 项目介绍

这是一个基于C++开发的高并发缓存系统，具备线程安全性，并支持多种缓存替换策略，包括LRU、LFU、ARC等。在基础的缓存算法之上进行了**并发性能优化**和缓存策略改进，以提高在**高并发场景**下的响应速度与命中率。

- 实现了**LRU**和**LFU**的缓存分片，降低锁争用，提升高并发访问下的性能；

- 实现了**LRU-k**优化，防止热点数据被冷数据替换，减少缓存污染问题；

- 实现了**LFU引入最大平均访问频次**，淘汰旧的热点数据，提升缓存的整体利用率；

- 实现了**ARC**策略，动态调整LRU和LFU的权重比例，提升复杂环境下的缓存命中率；





#### 4 请说说有哪些缓存算法？是否能手写一下LRU代码的实现？

缓存算法中，比较常见的如下：
FIFO(先进先出)
LRU(最近最少使用)
LFU(最不经常使用)
ARC(自适应替换)
CLOCK(时钟置换算法)



#### 5  常用的缓存工具和框架

分布式缓存：Redis、Memcached

Redis 最为主流和常用。

#### 6 为什么需要实现这个项目，使用缓存的目标是什么

在高并发系统中，频繁的请求往往会对后端数据库或服务造成巨大压力，导致响应延迟、系统瓶颈甚至崩溃。

使用缓存将热点数据保存在内存中，大量请求可以直接命中缓存，避免重复计算或频繁访问数据库

可以显著提升系统响应速度，降低数据库压力，提升用户体验

**适配不同访问模式**：本项目支持多种缓存替换策略（如 LRU、LFU、ARC），可根据业务特点灵活调整缓存逻辑，进一步提高命中率和数据利用率。

#### 7 多线程下如何保证线程安全？你使用了什么技术或方法来实现线程安全？

**使用 `std::mutex` 与 `std::shared_mutex` 控制访问同步**
 对于需要读写互斥的数据结构，采用 `std::shared_mutex` 实现读写分离，支持多个线程同时读取，提高读取性能；对于更新操作则使用独占锁，确保写操作的原子性和一致性。

**引入缓存分片机制降低锁粒度**
 将整个缓存划分为多个独立的分片（Shards），每个分片拥有独立的锁，避免全局锁造成的性能瓶颈。多线程访问时会根据 key 哈希定位到不同分片，从而大幅降低锁竞争。

**使用 `std::atomic` 进行无锁计数操作**
 对于命中率统计、访问频次计数等轻量级操作，使用 `std::atomic` 保证线程安全的同时避免加锁，提高执行效率。



#### 8 实现了哪些缓存策略？如何选择？各自的优缺点是什么？

- 实现了基础的LRU和LFU策略

- 实现了**LRU**和**LFU**的缓存分片，降低锁争用，提升高并发访问下的性能；

- 实现了**LRU-k**优化，防止热点数据被冷数据替换，减少缓存污染问题；

- 实现了**LFU引入最大平均访问频次**，淘汰旧的热点数据，提升缓存的整体利用率；

- 实现了**ARC**策略，动态调整LRU和LFU的权重比例，提升复杂环境下的缓存命中率；

优缺点：



#### 9 如何存储缓存数据？数据结构是如何设计的？

使用unordered_map作为快速查找的基础，用来快速定位缓存项。`Key` 是缓存键，`value` 是指向链表节点的指针（如 `shared_ptr`）；

LRU使用双向链表来维护访问顺序，

- 每次访问（get/put）将节点移动到链表尾部（表示最近访问）；
- 链表头部是最久未使用的节点；



LFU使用一个**频率表**：`unordered_map<访问次数, 双向链表>`，每个频率对应一个链表；

每次访问时：

- 将节点从当前频率链表中移除；
- 访问计数加 1；
- 将节点插入到新的频率链表中（访问次数 + 1）；
- 如果某个频率链表为空，则清理它。



#### 10 每种缓存策略的时间复杂度和空间复杂度分别是多少？

LRU 使用哈希表和双向链表实现，`get` 和 `put` 操作需要进行哈希表的查找和链表的插入删除，时间复杂度为 O(1)。维护哈希表和链表，空间复杂度为 O(N)

LFU需要维护两个哈希表，空间也是O(N)，因为有哈希表的存在，事件也是O(1).



`get(key)` / `put(key, value)`：**O(1)** *均摊*

- ARC 维护四个链表：空间O(N)
  - `T1`、`T2`：分别表示最近使用和频繁使用的数据；
  - `B1`、`B2`：分别记录被替换的缓存历史；
- 每个操作涉及链表和哈希表维护，操作数较多但均摊可达 O(1)。

#### 11 你对 LRU 和 LFU 策略做了哪些优化？如何验证这些优化的效果？


LRU  LFU分片：降低锁争用，提升高并发访问下的性能.
LRU-k：解决热点数据被冷数据挤出问题。
LFU 增加最大平均访问频率：避免历史热点长期占用缓存。淘汰旧的热点数据，提升缓存的整体利用率；

#### 12 多线程高并发下，如何优化缓存的性能？

**使用 `std::mutex` 与 `std::shared_mutex` 控制访问同步**
 对于需要读写互斥的数据结构，采用 `std::shared_mutex` 实现读写分离，支持多个线程同时读取，提高读取性能；对于更新操作则使用独占锁，确保写操作的原子性和一致性。

**引入缓存分片机制降低锁粒度**
 将整个缓存划分为多个独立的分片（Shards），每个分片拥有独立的锁，避免全局锁造成的性能瓶颈。多线程访问时会根据 key 哈希定位到不同分片，从而大幅降低锁竞争。

**使用 `std::atomic` 进行无锁计数操作**
 对于命中率统计、访问频次计数等轻量级操作，使用 `std::atomic` 保证线程安全的同时避免加锁，提高执行效率。



#### 13如何评估缓存的性能？测试指标有哪些？

**命中率（Hit Ratio）**
 表示缓存命中的请求占总请求数的比例，是衡量缓存效果最直接的指标。
 公式：`命中率 = 命中次数 / 总请求次数`。命中率越高，说明缓存越有效。

**平均访问延迟（Average Latency）**
 测量每次缓存访问所需的平均时间，涵盖 `get`、`put` 等操作。延迟越低，说明缓存响应速度越快。

**吞吐量（Throughput）**
 表示单位时间内处理的请求数量，反映系统在高并发场景下的处理能力。吞吐量越高越好。

**内存使用率（Memory Usage Efficiency）**
 衡量缓存中实际有效数据占总内存的比例。内存利用率高，说明缓存资源没有被浪费。

**并发性能（Scalability under Concurrency）**
 测试在不同并发线程数下的响应时间和吞吐量，评估系统的扩展性和锁设计效率。

**缓存污染率（Cache Pollution Rate）**
 衡量短期大量冷数据是否影响了热点数据的留存，反映替换策略的合理性。

**冷启动性能（Cold Start Time）**
 指缓存从空开始构建时达到稳定状态（命中率或延迟）的时间，尤其重要于系统重启或首次部署场景。



#### 14 如何选择锁机制？为什么要降低锁的粒度？

**锁的粒度**指的是每次加锁所保护的资源范围。**粒度大（粗粒度）**意味着一次锁住更多资源，**粒度小（细粒度）**则尽可能只锁定实际操作所需资源。

降低锁的粒度可以减少锁竞争，提升系统吞吐量，降低等待时间。



选择锁机制

选择合适的锁机制要结合读写比例、访问模式和性能需求，常见的锁类型及使用场景如下：

| 锁类型                 | 说明                                                         | 适用场景                                 |
| ---------------------- | ------------------------------------------------------------ | ---------------------------------------- |
| `std::mutex`           | 标准互斥锁，独占式，适合读写都频繁的场景                     | 多线程写操作频繁，或修改共享状态         |
| `std::shared_mutex`    | 读写锁，允许多个线程同时读，写操作独占                       | 读远多于写的场景，如缓存读取             |
| `std::recursive_mutex` | 允许同一线程重复加锁，适用于递归函数或需要多次锁定同一资源的情况 | 有递归或复杂流程的锁定                   |
| `std::atomic`          | 原子变量，适合简单整型或布尔状态的并发修改                   | 计数器、状态标志、无锁优化等轻量并发控制 |



#### 15 如何同时支持 LRU、LFU 和 ARC 策略？用户如何选择不同的策略？

**定义统一的策略接口**
 通过定义一个抽象基类（如 `KICachePolicy<Key, Value>`），统一规定缓存应支持的核心接口，如 `put()`、`get()`、`remove()` 等。

**实现多种策略类**
 各种策略（如 `KLruCache`、`KLFUCache`、`KARCCache`）继承自这个接口，分别实现各自的缓存逻辑。

**运行时配置选择策略**
 用户可以在程序启动或创建缓存时，通过传入配置参数（如字符串 `"LRU"`、`"LFU"`、`"ARC"`）动态选择使用的策略。

#### 16 如果需要新增一种缓存策略，如何设计？

所有策略都实现了一个统一的抽象接口（比如 `ICachePolicy<Key, Value>`），所以你只需要创建一个新的类，继承并实现该接口：

#### 17 如何应对缓存穿透、缓存击穿和缓存雪崩问题？



#### 18 Redis的缓存淘汰策略





#### 19 什么是缓存污染，你是如何减少这个问题的？

**缓存污染**是指：**一些低频、临时、不重要的数据占用了缓存空间**，导致原本应该常驻缓存的**热点数据被替换掉**，从而降低了缓存命中率和系统性能。

**LRU-K 改进策略**

- 传统 LRU 只关注“最近一次访问”，容易被短期访问的冷数据干扰；
- **你实现了 LRU-K（如 LRU-2）**，只在某个键被访问超过 K 次后才加入缓存，提高了对真正“热点数据”的识别能力，**有效减少冷数据污染缓存的问题**。

**LFU 引入“最大平均访问频次”机制**

- 传统 LFU 容易保留“曾经很热但现在冷却”的旧数据；
- 增加了淘汰旧热点的逻辑，定期对频率做衰减或引入时间窗口，从而**减少被“过时热点”污染的问题**。

1. **ARC 策略的动态调整机制**
   - ARC 通过维护 LRU 和LFU区域（一个用于常用数据，一个用于最近数据），**动态平衡 LRU 和 LFU 权重**，从而在不同工作负载下自适应调整，**有效避免缓存污染**。

#### 20 你是如何实现缓存分片的

分片数量：

在构造函数中，通过 `sliceNum` 参数指定缓存分片的数量。

如果用户没有指定 `sliceNum`，则默认使用硬件支持的线程数 (`std::thread::hardware_concurrency()`)，以优化多线程环境下的并发性能。

分片容量：

每个缓存分片的容量是通过总缓存容量除以分片数量得到的：

使用 `std::vector` 来存储多个分片。每个分片都是一个 `LfuCache` 实例（假设 `LfuCache` 是实现了 LFU 策略的缓存类）。

每次 `put` 或 `get` 操作时，根据对 `key`进行哈希映射计算对应的分片索引



#### 21 在C++中，原子操作是如何实现线程安全的

`std::atomic` 通过调用底层的硬件原子指令（如CAS）来确保操作的不可分割性，这些指令天生就具有 **不可中断性**，能确保多个线程同时访问变量时，不会发生数据竞争。



22 





#### 23 在设计高并发缓存系统时，你考虑了哪些性能指标？

**命中率（Hit Ratio）**
 表示缓存命中的请求占总请求数的比例，是衡量缓存效果最直接的指标。
 公式：`命中率 = 命中次数 / 总请求次数`。命中率越高，说明缓存越有效。

**平均访问延迟（Average Latency）**
 每次缓存访问所需的平均时间，涵盖 `get`、`put` 等操作。延迟越低，说明缓存响应速度越快。

**吞吐量（Throughput）**
 表示单位时间内处理的请求数量，反映系统在高并发场景下的处理能力。吞吐量越高越好。

**扩展性**：设计时预留接口或配置支持动态调整缓存容量和分片数量，支持更高并发和更大数据量。

#### 24 你是如何优化缓存系统以提高高并发场景下的响应速度的？

**缓存分片（Sharding）**：将整体缓存按照哈希分成多个独立的分片，每个分片拥有自己的锁和数据结构，避免多个线程同时竞争同一个全局锁，显著降低锁冲突，提高并发度。

**调整数据结构**：结合使用哈希表（如 `std::unordered_map`）和双向链表（用于维护访问顺序）来快速定位和更新缓存项；

**原子操作**：对于轻量级的操作，使用原子变量代替互斥锁，减轻锁的粒度。



#### 25 你是如何确保在高并发环境下数据的一致性的？

**使用细粒度锁**：将整体缓存划分为多个分片（Sharding），每个分片维护独立的数据结构和互斥锁。当访问或修改某个键值时，仅锁定其所在的分片，而不是全局锁，避免不必要的锁竞争，从而既保证线程安全，又提升并发性能。

**使用原子操作**：对于访问计数、状态标志等简单的共享数据，使用 `std::atomic` 类型并结合底层的 CAS（Compare-And-Swap）原子指令，实现无锁的数据修改。这种方式避免了加锁开销，同时确保了修改过程的原子性和一致性。



#### 26 在C++中，你是如何管理内存的？

**使用智能指针（`std::shared_ptr`、`std::unique_ptr`）**：
 通过智能指针自动管理对象生命周期，在对象不再使用时自动释放内存，有效避免了内存泄漏和悬空指针的问题。

**遵循 RAII（资源获取即初始化）原则**：
 将资源的申请与释放封装在对象生命周期中，例如在构造函数中分配资源，在析构函数中自动释放，确保异常安全和资源及时释放。

**缓存系统中定期清理无用数据**：
 结合 LRU、LFU 等淘汰策略，在缓存达到上限或数据失效时及时移除不常用数据，避免内存占用增长失控。

**预分配内存池**：
 对于高频率使用的小对象，使用内存池统一管理分配和释放，减少 `new/delete` 带来的系统开销，提升性能并避免内存碎片化。



#### 27 你是如何实现缓存的预热功能的？

**预加载策略**：在系统启动时，通过分析历史访问日志、热点数据统计或业务规则，**提前识别出常用或高频访问的数据，并将这些数据加载到缓存中。**

**实现方式**：提供显式的预热接口，如通过配置文件或初始化代码中调用 `cache.put(key, value)`，将关键数据手动写入缓存。例如：

优势：

避免系统刚启动时因缓存为空而导致的“缓存击穿”。

减少冷启动阶段对后端数据库或服务的压力。

提升系统响应速度，优化用户首次访问体验。

#### 28 在实现缓存分片时，你是如何确定分片数量的？



**根据 CPU 核心数**：**默认情况下，将分片数量设置为系统的 CPU 核心数**（如通过 `std::thread::hardware_concurrency()` 获取），以充分利用多核处理能力，减少锁竞争，提高并发性能。

**结合并发量与负载评估**：对于高并发或负载较大的系统，通过压测分析系统瓶颈，根据实际情况适当增加分片数量，确保各个分片的访问压力更均衡，从而提升整体吞吐能力。

**哈希函数结合分片数分布数据**：**通过哈希函数将 key 均匀映射到不同的分片，避免出现数据倾斜或热点集中问题**。分片数的选择要兼顾哈希函数的散列效果，确保缓存命中和替换策略的效率不会受影响。





#### 29 你是如何确保缓存系统在面对突发流量时的稳定性的？



1. **负载均衡**：**通过将缓存系统设计为多分片结构，结合哈希函数，将请求均匀分散到各个缓存实例上**，防止单点压力过高，从而提升整体抗压能力。
2. **熔断与降级机制**：**在缓存访问失败或响应超时过多的情况下，系统会触发熔断逻辑，暂时绕过缓存，直接返回默认值或空数据**，避免缓存系统进一步被压垮，同时保障主业务流程不中断。
3. **提前扩容**：根据历史访问量、时间段流量模型等预测突发高峰，在流量到达前动态增加缓存容量或实例数（如增加分片数或部署更多缓存节点），确保在高并发冲击下仍有足够的承载能力。







#### 可以添加的其它接口

✅ 基础操作接口

| 接口名            | 说明                                             |
| ----------------- | ------------------------------------------------ |
| `put(key, value)` | 插入或更新缓存项                                 |
| `get(key)`        | 获取缓存值，命中则返回，未命中返回 null/optional |
| `remove(key)`     | 删除指定缓存项                                   |
| `contains(key)`   | 判断 key 是否存在于缓存中                        |
| `clear()`         | 清空整个缓存                                     |



------

✅ 过期控制接口（可选）

| 接口名                 | 说明                                        |
| ---------------------- | ------------------------------------------- |
| `put(key, value, ttl)` | 设置带过期时间的缓存项（TTL: Time To Live） |
| `set_ttl(key, ttl)`    | 修改已有 key 的过期时间                     |
| `get_ttl(key)`         | 查询某个 key 的剩余有效时间                 |
| `expire(key)`          | 手动让 key 立即过期                         |



------

✅ 缓存策略/状态接口（用于调试或监控）

| 接口名             | 说明                                     |
| ------------------ | ---------------------------------------- |
| `size()`           | 当前缓存项数量                           |
| `capacity()`       | 缓存最大容量（如最大条数或内存限制）     |
| `hit_count()`      | 命中次数（可用于计算命中率）             |
| `miss_count()`     | 未命中次数                               |
| `eviction_count()` | 被淘汰的缓存项总数                       |
| `stats()`          | 返回缓存整体运行指标（如命中率、大小等） |























































## 协程项目

本项目为了实现服务端IO密集型任务的处理，在Linux环境下使用C++开发了一个协程库。
 项目主要实现了协程和协程调度器，定时器等。同时，对常见的系统的API，如sleep、socket网络编程，和Sockt IO系类接口API进行了hook，实现非阻塞异步的效果。

#### 什么是协程

协程也可以叫做”轻量级的线程，用户线程“。
 简单的理解协程，协程一种执行过程中能够yield(暂停)和resume(恢复)的子程序，也可以说是协程就是函数和函数运行状态的组合，怎么理解？正常的函数在执行中是直接就执行完成了中间不会有多余的步骤，更不会说我这个函数执行到一半就去执行其他函数了，但是协程不一样，我们使用协程首先要绑定一个入口函数，并且可以在函数的任意位置暂停去执行其他其他的函数，再回来执行暂停的函数，所以说协程是函数和函数运行状态的组合(协程需要绑定入口函数，协程记录了函数的运行状态)。



那么协程是如何做到让函数暂停和让函数的恢复呢？
这个是因为协程的记录会有协程上下文，协程执行yield的时候协程上下文记录了协程暂停的位置，当resume的时候就是从暂停的地方恢复。协程上下文包含了函数在当前状态的全部cpu寄存器的值，这些寄存器记录函数的栈帧、代码执行的位置等信息，如果把这些值交给cpu去执行那么就会实现从函数暂停的地方去恢复执行。



#### 对称协程  非对称协程

对称协程运行协程之间直接相互调用和切换，控制流(执行权拿到执行权的协程才可以执行)可以在多个协程之间自由的转移。这种协程中协程之间是平等的，它们可以相互调用对方，类似于函数调用。每个协程可以显示的决定将控制权转移到那个协程。



其中存在一个主协程（或称为调度器），并且其他协程是从主协程或调度器中被调用的。不能指定调度到哪一个协程。



#### 有栈协程  无栈协程 









#### 你的协程是N-M多对多关系，你是怎么实现的

**N**：代表系统中有 N 个 OS 线程（例如你启动了 4 个线程）；

**M**：代表调度器中注册了 M 个协程任务（这些任务可能是 Fiber 对象或函数回调）；

**N:M**：表示 **M 个协程被均匀调度在 N 个线程上执行**，每个线程都可以运行任意协程。

所有待执行任务（协程或回调函数）统一存放在一个共享任务队列中，多个线程通过循环不断抢占任务执行，

空闲线程会执行 idle 协程挂起等待，当有新任务加入时，通过 tickle 机制唤醒空闲线程



#### 如何管理协程，他们是怎么切换的

协程由 `Fiber` 类封装，一个协程就是一个 `Fiber` 实例。

创建时你传入的是一个 `std::function<void()>` 类型的回调函数，这个函数是协程的实际任务逻辑。

每个 `Fiber` 都拥有自己的一块栈空间（通过 `malloc` 分配）和自己的上下文 `m_ctx`，用于保存协程的执行状态。

协程上下文的创建 保存 切换由ucontext族函数完成

协程的切换由resume（恢复）和yield（挂起完成）。（交换上下文，切换状态）



#### 你提到的协程与epoll结合，是如何结合的

当某个 socket I/O 操作因不可用（如 `EAGAIN`）而暂时无法完成时，程序会把当前协程挂起，并通过 `IOManager::addEvent()` 将该 fd 和事件（如 READ 或 WRITE）注册到 `epoll` 中，**协程让出执行权，等待 IOManager::idle() 中的 `epoll_wait` 监听事件发生**。一旦事件就绪，`idle()` 会唤醒对应的协程并重新调度执行，从而实现非阻塞、协程友好的 I/O 操作。

 

#### 定时器是怎么实现的

一个基于**红黑树（std::set）管理的时间堆机制**，用于按超时时间自动触发回调函数。每个定时器（`Timer`）记录自身的超时时间和回调逻辑，支持取消（`cancel`）、刷新（`refresh`）、重设（`reset`）等操作；所有定时器由 `TimerManager` 管理，按触发时间排序。通过定时扫描最早到期的定时器（`getNextTimer` 和 `listExpiredCb`），实现高效定时调度。采用红黑树而非堆，是为了支持**快速插入、删除、更新和查找任意定时器**，满足灵活管理的需求。



#### 协程调度器是怎么实现的

协程调度器通过创建多个线程（N），每个线程运行一个主循环，不断从全局任务队列中取出协程（Fiber）或回调函数执行，并在没有任务时运行空闲协程。

























































