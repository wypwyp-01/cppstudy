



### 整体性问题

#### 一条查询语句的执行流程

- 连接器：建立连接，管理连接，校验用户身份。
- 查询缓存：查询语句如果命中缓存则直接返回，否则继续往下执行。
- 词法分析：解析SQL，根据输入的查询语句提取出关键词
- 语法分析：根据词法分析的结果，判断输入的语句是否满足语法规则。没问题就会构造出语法树，方便后续模块读取表名、字段名，语句类型等。
- 执行SQL分三个阶段：
  - 预处理器：查询表名是否存在，把*扩展为表格所有列
  - 优化器：负责将SQL查询语句的执行方案确定下来。基于查询成本的考虑，选择查询成本最小的执行计划。（单表查询，索引的选择，多表查询：表的连接方式的选择。）
  - 执行器：根据执行计划执行SQL查询语句，从 存储引擎读取数据，返回给客户端







#### mysql和redis的区别？

数据存储方式：MySQL：数据以表格的形式以行和列的方式存储在磁盘上，支持复杂的关系型数据模型。Redis：数据存储在内存中，因此具有更快的读写速度，但受到内存容量的限制。

数据类型：MySQL：支持各种数据类型，包括整型、浮点型、字符型、日期型等。Redis：支持丰富的数据类型，如字符串、列表、集合、哈希表、有序集合等，适合用于缓存、消息队列等场景。

持久化：MySQL：支持持久化存储数据，数据可以在磁盘上持久保存。Redis：可以选择是否持久化数据，支持RDB快照和AOF日志两种持久化方式。

应用场景：MySQL：适用于需要复杂查询和事务支持的应用，如企业级应用、电子商务平台等。Redis：适用于对速度要求较高、数据量较小、对数据结构要求较高的场景，如缓存、计数器、实时排行榜等。



#### 有了mysql，为什么还要有Redis



#### 什么是MongoDB，与mysql区别

MongoDB是一种**非关系型数据库（NoSQL）**，属于**文档型数据库**。它使用**JSON风格的文档**（称为BSON）来存储数据，每个文档可以包含不同类型和数量的字段。

| **特性**       | **MongoDB**                                        | **MySQL**                          |
| :------------- | :------------------------------------------------- | :--------------------------------- |
| **数据模型**   | 文档型（JSON风格的BSON文档）                       | 关系型（表格、行、列）             |
| **灵活性**     | 高（动态数据模型，字段可以不同）                   | 低（表结构固定，修改成本高）       |
| **事务支持**   | 有限（支持单文档事务，MongoDB 4.0+支持多文档事务） | 完整（支持ACID特性，适合复杂事务） |
| **性能**       | 高（适合读写密集型应用，支持水平扩展）             | 适合事务性应用（垂直扩展为主）     |
| **查询语言**   | 类似SQL的查询语言（MongoDB查询语言）               | SQL（结构化查询语言）              |
| **扩展性**     | 水平扩展（Sharding）                               | 垂直扩展（增加服务器性能）         |
| **适用场景**   | 大数据、日志分析、实时分析、内容管理系统           | 电子商务、金融系统、事务性应用     |
| **数据完整性** | 依赖应用层逻辑（如唯一性约束）                     | 数据库层支持（如外键、约束）       |
| **复杂查询**   | 支持聚合查询，但复杂性有限                         | 支持复杂的JOIN查询和事务处理       |



#### 关系型数据库，非关系型数据库，区别

关系型数据库是一种使用**表格（Table）**来组织数据，每个表格由**行（Row）**和**列（Column）**组成，每一列都有固定的名称和数据类型。数据之间的关系通过**外键（Foreign Key）**或**连接查询（JOIN）**来实现。

非关系型数据库（NoSQL）是一类不基于传统关系模型的数据库，它们通常用于处理大规模、动态的数据集，强调高性能、高可用性和水平扩展能力。NoSQL数据库有多种类型，包括文档型、键值型、列族型和图数据库。

| **特性**             | **关系型数据库（RDBMS）**      | **非关系型数据库（NoSQL）**                        |
| :------------------- | :----------------------------- | :------------------------------------------------- |
| **数据模型**         | 表格、行、列，结构固定         | 动态数据模型（文档、键值对、列族、图）             |
| **事务、一致性模型** | 支持事务，强一致性（ACID）     | 事务支持有限，弱一致性（CAP定理，最终一致性）      |
| **查询语言**         | SQL（结构化查询语言）          | 多样（如MongoDB查询语言、Redis命令行）             |
| **扩展性**           | 垂直扩展（增加服务器性能）     | 水平扩展（分布式架构）                             |
| **性能特点**         | 适合事务性操作，性能受限于单机 | 适合高并发、大数据场景，性能高                     |
| **适用场景**         | 事务性应用（如金融、电商）     | 大数据、实时分析、动态数据模型（如日志、内容管理） |



关系型数据库：

表结构，⽋缺灵活度

优点：易于理解；通⽤SQL语⾔使得操作关系型数据库⾮常⽅便；丰富的完整性；必须具有ACID特性

缺点：并发量⾼，磁盘I/O限制瓶颈；每天产⽣的数据多，查询效率低；难以进⾏横向

扩展，升级扩展时候需要进⾏停机维护和数据迁移

MySQL、Oracle

⾮关系型数据库：

存储key-value形式，⽂档形式，图⽚形式

优点：查询速度快，根据键值对就可以完成查询，不需要进⾏多表联合查询；

缺点：只适合⼀些简单的数据，较复杂查询时候适合关系型数据库

MongoDB（⽂档型）、Redis（key-value型）、Memcached

### 基础语法问题

#### 三范式

第一范式（1NF：First Normal Form）
定义：确保数据库表中的每一列都是不可再分的原子数据项，即表中的每个字段都必须是不可分割的最小数据单位。

| StudentID | Name  | Courses            |
| :-------- | :---- | :----------------- |
| 1         | Alice | Math, Science      |
| 2         | Bob   | History, Geography |

| StudentID | Name  | Course    |
| :-------- | :---- | :-------- |
| 1         | Alice | Math      |
| 1         | Alice | Science   |
| 2         | Bob   | History   |
| 2         | Bob   | Geography |

第二范式

在满足第一范式的基础上，确保表中的每个非主属性（非键字段）都完全依赖于主键（一个表只说明一个事物，仅适用于复合主键）。

| OrderID | ProductID | ProductName | Quantity |
| :------ | :-------- | :---------- | :------- |
| 101     | 1         | Apple       | 2        |
| 101     | 2         | Banana      | 3        |
| 102     | 3         | Orange      | 1        |

**改进**： **Orders 表**：

| OrderID | ProductID | Quantity |
| :------ | :-------- | :------- |
| 101     | 1         | 2        |
| 101     | 2         | 3        |
| 102     | 3         | 1        |

**Products 表**：

| ProductID | ProductName |
| :-------- | :---------- |
| 1         | Apple       |
| 2         | Banana      |
| 3         | Orange      |

第三范式：⾮主键字段不能相互依赖（不存在传递关系）

#### 反范式

反范式是指故意违反范式规则，将多个表中的数据合并到一个表中，或者在表中重复存储某些数据，以减少查询时的连接操作或计算量，从而提高查询性能。

eg：单价*数量=⾦额，但是多⼀列⾦额可以提⾼查询速度



#### 数据类型？

整数类型：

TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT（1字节、2字节、3字节、4字节、8字节）；

实数类型：

FLOAT、DOUBLE、DECIMAL（存储⽐BIGINT还⼤的整型，能存储精确的⼩数）

字符串类型：

VARCHAR、CHAR、TEXT、BLOB

尽量避免使⽤TEXT/BLOB类型，查询时会使⽤临时表，导致严重的性能开销。

枚举类型：ENUM

ENUM存储⾮常紧凑，会把列表值压缩到⼀个或两个字节；ENUM在内部存储时，其实存的是整数。

尽量避免使⽤数字作为ENUM枚举的常量，因为容易混乱

⽇期和时间类型：尽量使⽤timestamp，空间效率⾼于datetime；如果需要存储微秒，可

以使⽤bigint存储

- **`DATETIME`**：
  - 格式：`YYYY-MM-DD HH:MM:SS`。
  - 用途：存储日期和时间。
- **`TIMESTAMP`**：
  - 格式：`YYYY-MM-DD HH:MM:SS`。
  - 实际存储的是时间戳

#### drop、delete、truncate区别？

| 特性/功能    | `DELETE`                                   | `TRUNCATE`                           | `DROP`                               |
| :----------- | :----------------------------------------- | :----------------------------------- | :----------------------------------- |
| **功能**     | 删除表中的数据行，保留表结构               | 清空表中的所有数据，保留表结构       | 删除表及其所有数据和结构             |
| **事务支持** | 支持，可回滚                               | 不支持，不可回滚                     | 不支持，不可回滚                     |
| **触发器**   | 触发 `BEFORE DELETE` 和 `AFTER DELETE`     | 不触发任何触发器                     | 不触发任何触发器                     |
| **性能**     | 较低，逐行删除，记录到事务日志             | 较高，直接重置表结构，不记录每行删除 | 最高，直接删除表结构，不记录任何操作 |
| **用途**     | 根据条件删除部分行，或清空数据但保留表结构 | 快速清空表中所有数据，保留表结构     | 完全删除表及其所有内容               |

#### SQL约束（对表中数据的⼀种约束）？

表中数据的限制条件，保证表中的记录完整性和有效性

NOT NULL：⾮空约束

UNIQUE：唯⼀约束

PRIMARY KEY：主键约束，不能重复不能为空

FOREIGN KEY：外键约束

CHECK：检查约束，检查数据表中字段值有效性

DEFAULT：默认值约束

#### varchar和test区别

| 特性/功能    | `VARCHAR`                        | `TEXT`                                                      |
| :----------- | :------------------------------- | :---------------------------------------------------------- |
| **性能**     | 高效，适合短字符串               | 性能较低，适合长字符串                                      |
| **存储方式** | 可变长度，行内存储               | 固定格式，数据存储在独立区域，表中存储指针                  |
| **最大长度** | 最大 65,535 字节（受限于行大小） | 最大 65,535 字节（`TEXT`），`MEDIUMTEXT` 和 `LONGTEXT` 更大 |
| **索引支持** | 可以被索引，索引效率高           | 不直接支持索引，但可以创建前缀索引                          |
| **适用场景** | 短字符串，如用户名、地址         | 长文本，如文章、日志                                        |
| 默认值       | 支持默认值                       | 不能有默认值                                                |

#### char和varchar区别

| 特性/功能    | `CHAR`                             | `VARCHAR`                            |
| :----------- | :--------------------------------- | :----------------------------------- |
| **存储方式** | 固定长度，自动填充空格             | 可变长度，不填充空格                 |
| **存储空间** | 总是占用声明的长度                 | 占用实际内容长度 + 1 或 2 字节       |
| **性能**     | 存储和读取速度快，适合固定长度数据 | 存储和读取速度略低，适合长度变化数据 |
| **适用场景** | 长度固定或变化不大的字符串         | 长度变化较大的字符串                 |
| **索引效率** | 通常更适合创建索引                 | 索引效率略低，但节省空间             |

#### in和exists的区别











### 存储引擎

#### 存储引擎有哪些？各有什么特点

InnoDB存储引擎：支持事务处理，支持外键，支持崩溃修复能力和并发控制。如果需要对事务的**完整性**要求比较高（比如银行），要求实现并发控制（比如售票），那选择InnoDB有很大的优势。如果需要**频繁的更新、删除操作**的数据库，也可以选择InnoDB，因为支持事务的提交（commit）和回滚（rollback）。

MyISAM存储引擎：插入数据快，空间和内存使用比较低。如果应用的**完整性、并发性要求比较低**，也可以使用。如果数据表主要用来**插入和查询**记录，则MyISAM引擎能提供较高的处理效率

MEMORY存储引擎：所有的数据都在内存中，数据的处理速度快，但是安全性不高。它对表的大小有要求，不能建立太大的表。MySQL中使用该引擎作为临时表，存放查询的中间结果。

#### INNODB和MYISAM区别

| 特性/功能        | InnoDB                                                       | MyISAM                                                       |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **事务支持**     | 支持事务（ACID特性），支持回滚、提交和崩溃恢复               | 不支持事务，无法保证事务的原子性、一致性、隔离性和持久性     |
| **锁机制**       | 行级锁（row-level locking），适合高并发写操作                | 表级锁（table-level locking），适合读多写少的场景            |
| **索引**         | 主键索引是聚簇索引，B+tree为索引结构，数据和索引在一颗树上。 | ⾮聚簇索引，B+tree为索引结构，索引数据分离，索引保存的是数据⽂件指针 |
| **崩溃恢复能力** | 在⼀起；不⽀持全⽂索引支持，通过事务日志（redo log）恢复数据 | 不支持，崩溃后需要手动修复表，修复过程可能复杂且耗时         |
| **性能**         | 写操作性能在高并发场景下优于 MyISAM，读操作性能稍逊但可通过优化弥补 | 读操作性能高，尤其是全表扫描；写操作在低并发场景下性能较好，但高并发时容易锁冲突 |
| **全文索引支持** | 支持（自 MySQL 5.6 开始）                                    | 支持，但功能相对有限                                         |
| **适用场景**     | 需要事务支持、高并发写操作、数据一致性的场景（如金融系统、电商平台） | 读多写少的场景（如日志记录、数据报表）                       |
| **其他特性**     | 支持外键约束，维护表间关系；支持 MVCC（多版本并发控制）      | 不支持外键约束；表级锁导致并发写操作性能受限                 |

#### 自适应哈希索引

innodb存储引擎会监听对表上各个页的查询，当观察到其中某个页是热点数据（访问次数满足条件），则自动为数据页建立哈希索引

- **仅支持等值查询**：自适应哈希索引只能用于等值查询（如 `=`、`IN`），不支持范围查询或排序操作。
- **内存消耗**：构建和维护哈希索引需要额外的内存开销。

#### 双写缓冲区

双写缓冲区（Doublewrite Buffer） 是一个位于 磁盘 上的存储区域。它主要用于解决部分写问题（Partial Page Write），确保数据页在写入磁盘时的完整性和一致性。

当 InnoDB 需要将脏页从 Buffer Pool 刷盘时，数据不会直接写入表空间，而是先经过 Doublewrite Buffer。这一过程分为两个阶段：
• 第一阶段：写入 Doublewrite Buffer
◦ Doublewrite Buffer 是位于系统表空间的一段连续区域。
◦ 脏页以批量形式顺序写入 Doublewrite Buffer。
• 第二阶段：写入实际表空间
◦ 确保 Doublewrite Buffer 写入成功后，InnoDB 再将数据页随机写入实际表空间。



提⾼了⻚写回的效率，内存中的page在disk中不⼀定连续，写⼊到DWB可以实现连续写，提⾼了效率

弊端：开辟额外的内存和磁盘空间

#### change buffer

当对非唯一二级索引执行插入、更新或删除操作时：
• 如果目标索引页在缓冲池（Buffer Pool）中，直接更新该页。
• 如果目标索引页不在缓冲池中，InnoDB 会将这些变更记录到 Change Buffer 中。（减少随机IO）。
主键索引（聚簇索引）和唯一索引 不适用 Change Buffer，因为它们需要即时验证唯一性。

#### BUFFER POOL

⼀块内存区域，为了提⾼数据库的性能，数据库操作数据的时候，把硬盘上的数据加载到buffer pool，不直接和硬盘打交道，操作的是 buffer pool ⾥⾯的数据，数据库的增删改查都是在 buffer pool 上进⾏。

BUFFER POOL也是以页为单位的，每页的大小是16KB。

为管理这些缓存页，为每一个缓存页创建控制块，放在buffer pool的最前面。



如何管理空闲页：使用链表，把空闲页的控制块作为链表的节点（每个控制块包含对应缓存页的地址）。称为Free链表。

如何管理脏页：Flush链表。链表的节点也都是控制块，且都是脏页。后台线程不建立Flush链表，将脏页写入磁盘。

如何提高缓存命中率：LRU链表。管理脏页 + 干净页。将最近且经常查询的数据缓存在其中，不经常使用的数据淘汰出去。



普通的LRU算法并没有被MYSQL使用，因为无法解决以下问题：

1、预读失效 2、BUFFER POOL污染

解决1：将LRU链表划分为YOUNG和OLD两个区域（63:37），被预读的页，先放入到OLD区域的头部，页被访问时，才进入到YOUNG区域头部。

解决2：当**「页被访问」且「 old区域停留时间超过innodb_old_blocks_time阈值（默认为1秒)」**时，才会将页插入到young区域，否则还是插入到old区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。

#### 预读失效：

预读：利用局部性原理，在加载数据页时，会把相邻的页一并加载进来。被提前加载进来的页，没有被访问，就是预读失效。（会导致预读也占据了LRU链表头的位置，而链表尾部被淘汰的也可能是频繁被访问的页）。

#### BUFFER POOL污染

当**某一个SQL语句扫描了大量的数据**时，在Buffer Pool空间比较有限的情况下，可能会将**Buffer Pool里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘IO，MySQL 性能就会急剧下降，这个过程被称为Buffer Pool污染。

#### 脏页刷盘时机

当redo log日志满了的情况下，会主动触发脏页刷新到磁盘;
Buffer Pool空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘;
MySQL认为空闲时，后台线程会定期将适量的脏页刷入到磁盘;
MySQL正常关闭之前，会把所有的脏页刷入到磁盘;











### 索引



#### 什么是索引

索引是帮助存储引擎快速获取数据的一种数据结构，索引就是数据的目录。

#### 为什么使用索引：

通过创建唯一索引，可以保证数据库表中每一行数据的唯一性。

可以大大加快数据的查询速度。

加快数据的排序以及分组速度，避免服务器进行排序以及临时表的产生。





## 索引分类

### 按照数据结构分类

#### 哈希索引

- **哈希索引**，对于哈希索引来说，底层的数据结构肯定是哈希表，因此**在绝大多数需求为单条记录查询**的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择B+树索引。

- Hash索引只能用于精确查询(=，in)，不支持范围查询（between，>，< ，...）

- 无法利用索引完成排序操作

- 查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索

  引

#### B+树

B+树是一种多叉查找树，所有的数据都会出现在叶子节点。

非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。每个结点里的数据按照主键顺序存放。

叶子节点形成一个双向链表。



B+树存储千万级的数据只需要3-4层高度，意味着查找千万行记录的表只需要三四次磁盘IO。





#### 为什么 MySQL InnoDB 选择 B+tree 作为索引的数据结构？

1、B+Tree vs B Tree
B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。
另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。
2、B+Tree vs 二叉树
对于有 N 个叶子节点的 B+Tree，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。
在实际的应用当中， d 值是大于100的，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，也就是说一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到目标数据。
而二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，这已经比 B+Tree 高出不少，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。
3、B+Tree vs Hash
Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。
但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。







#### 主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：（按照物理存储分类）

• 主键索引（聚簇索引）的 B+Tree 的叶子节点存放的是**实际数据**，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；**必须有 只能有一个。**
• 二级索引的 B+Tree 的叶子节点存放的是**主键值和索引列的值**，而不是实际数据。**可以有多个。**



MyISAM⽆论主键索引还是⼆级索引都是⾮聚簇索引，InnoDB主键索引是聚簇索引，⼆级索引是⾮聚簇索引



#### ⾮聚簇索引⼀定会回表吗？

不⼀定，如果包含了所有需要查询字段的值（覆盖索引）就不回表

#### 回表查询

先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取数据的方式，就称之为回表查询。要查两个B+树才能找到数据。

#### 覆盖索引

**在二级索引的 B+Tree** 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。



#### 按照字段特性分类

**主键索引**
主键索引就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。

**唯一索引**
唯一索引建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。

**普通索引**

普通索引就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。

**前缀索引**
前缀索引是指对**字符类型字段的前几个字符**建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。
使用前缀索引的目的是为了**减少索引占用的存储空间**，提升查询效率。

#### 按照字段个数分类

**单列索引**

建立在**单个列**上的索引称为单列索引，比如主键索引；

**联合索引**

通过将**多个字段组合在一起**形成一个索引，该索引就被称为联合索引。

#### ﻿最左前缀法则：

对于联合索引，要遵循最左前缀法则。查询要从索引最左边的列开始，并且不跳过索引中的列，如果跳过某一列，后面的字段将会失效。

```
# 存在(a,b,c)的索引
#a,b⾛索引
where a = 1 and b = 1
#b没触发，c也不⾛索引
where a = 1 and c = 1
#a没触发，b,c都不⾛索引
where b = 1 and c = 1
```

- mysql会优化where子句后面的列的顺序。

#### 联合索引范围查询

联合索引中，出现范围查询(>,<)，范围查询右侧的列索引失效。

**联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配**



#### 索引下推

**尽可能在存储引擎层就利用索引过滤掉不符合条件的行，减少回表操作，提升查询效率。**

在执行 select * from table where a > 1 and b = 2 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足

- 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。
- 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，**减少回表次数**。
- 当查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。



#### 索引区分度

建立联合索引时的字段顺序，对索引效率也有很大影响。**越靠前的字段被用于索引过滤的概率越高**，实际开发工作中建立联合索引时，要**把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到**。

区分度就是某个字段 column 不同值的个数「除以」表的总行数，计算公式如下：

![image-20250226101833865](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250226101833865.png)

#### 索引优缺点：

索引最大的**好处是提高查询速度、提高排序效率、提高分组效率、加快表之间的连接、实现唯一性约束**，但是索引也是有缺点的，比如：
• 需要占用物理空间，数量越大，占用空间越大；
• 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；
• 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。

#### 如何创建索引

CREATE INDEX命令创建

```sql
CREATE UNIQUE INDEX idx_email ON user(email);
```

创建表时创建索引

```sql
CREATE TABLE product (
  id INT PRIMARY KEY,
  name VARCHAR(100),
  category_id INT,
  INDEX idx_category(category_id)
);
```

**使用 `ALTER TABLE` 添加索引**

```sql
ALTER TABLE user ADD INDEX idx_username(username)
```





#### 创建索引时需注意什么 && 创建索引的原则

**⾮空字段**：指定列为NOT NULL，MySQL中含有空值的列很难进⾏查询优化，⽤0/特殊值空串替代空值

选择合适的字段

- **比如说频繁出现在 WHERE、JOIN、ORDER BY、GROUP BY 中的字段**。
- **优先选择区分度高的字段**，比如用户 ID、手机号等唯一值多的，而不是性别、状态等区分度极低的字段，如果真的需要，可以考虑联合索引。

**要控制索引的数量，避免过度索引**，每个索引都要占用存储空间，单表的索引数量不建议超过 5 个。

**索引字段⼩好，IO次数少**

**联合索引的时候要遵循最左前缀原则**，即在查询条件中使用联合索引的第一个字段，才能充分利用索引。

**区分度高的字段放在左侧**，**等值查询的字段优先于范围查询的字段**。例如 `WHERE A=1 AND B>10 AND C=2`，优先 `(A, C, B)`。

如果联合索引包含查询的所需字段，还可以避免回表，提高查询效率。



#### 索引的使用场景 && 什么时候适用索引？

字段有**唯一性限制**的，比如商品编码；



经常用于 **WHERE 查询**条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。

经常用于 **GROUP BY 和 ORDER BY** 的字段，这样在查询的时候就不需要再去做一次排序了

**用于 `UPDATE` 和 `DELETE` 的条件列应建索引**。

**去重字段建索引**：如用于 `DISTINCT` 的字段。

**多表 `JOIN` 的连接字段建索引**：尤其是连接字段和 `WHERE` 条件字段。



**联合索引优于多个单列索引**：多个字段都需索引时优先考虑联合索引。

**联合索引最左优先原则**：频繁使用的列应放在联合索引的最左侧。



**字符串字段用前缀建索引**：避免整字段建索引以节省空间。

**优先选择类型小的列建索引**：节省空间、提高效率。

**选择区分度高（散列性好）的列建索引**：能更有效提高查询性能。



#### 什么时候不需要创建索引？

• WHERE 条件，GROUP BY，ORDER BY 里用不到的字段
• 字段中存在大量重复数据，不需要创建索引，比如性别字段
• 表数据太少的时候，不需要创建索引；
• 经常更新的字段不用创建索引，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。



#### 主键索引最好是自增的

- 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。
- 如果我们使用非自增主键，由于每次**插入主键的索引值都是随机**的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为**页分裂**。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率

#### 索引最好设置为not null

- 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。
- 第二个原因：NULL 值是一个没意义的值，但是它会**占用物理空间**，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么**至少会用 1 字节空间存储 NULL 值列表**

#### 

#### 索引失效的情况

对索引使用左或左右模糊匹配

对索引使用函数

对索引列进行表达式计算

对索引进行隐式类型转换（如字符串不加引号）

- （MYSQL在遇到字符串和数字比较的时候，会自动把字符串转换为数字，然后再进行比较）

联合索引不遵守最左匹配原则

OR引起：or前⾯的条件中的列有索引，后⾯的没有，所有列的索引都不会被⽤到

联合索引中范围查询（）后面的索引会失效







#### 怎么优化索引

前缀索引优化

覆盖索引优化

主键索引最好自增

防止索引失效



#### 怎么查看有没有⽤到索引？

EXPLAIN语句

possible_key：查询中可能⽤到的索引

key：当前查询真正使⽤的索引





#### 索引一定能提高查询性能吗

| **小表**                       | 表本身数据量不大，**全表扫描比走索引还快**（省掉随机 IO）。  |
| ------------------------------ | ------------------------------------------------------------ |
| **回表成本高**                 | 二级索引命中后还要回表取数据，**频繁随机 IO 反而变慢**。     |
| **选择性差**                   | 比如 `性别 = '男'`，**大量重复值**，扫描数据反而比用索引快。 |
| **索引命中率高且需要回表查询** |                                                              |





#### 单表访问方法

**const**

```
WHERE unique_column = 'value'
```

主键或唯一二级索引进行等值查询

最多匹配一条记录

**ref**

普通二级索引进行等值查询

查询结果可能有多条

`where ket1 = 'abc'`

**range**

```
WHERE column BETWEEN x AND y 或 WHERE column > x
```

使用索引进行查询时，对应的扫描区间为**若干个单点扫描区间或者范围扫描区间**

**index**

描述：index 是一种**全索引扫描**的访问方法。数据库会**扫描整个索引，而不是表的每一行**。
• 适用场景：
◦ 查询条件没有明确的范围或等值条件，但索引可以覆盖查询列。
◦ 索引扫描比全表扫描更高效，尤其是当表很大但索引较小时。

**all**

全表扫描



#### explain输出计划中各列的解释

**table**

每条记录都代表单表访问的方法，table就是该表的表名

**id**

查询中每出现一个select关键字，就会分配一个唯一的id。

**type**

对于单表的访问方法

**possible_keys 和keys**

可能用到的索引有哪些

实际用到的索引

**extra**





### 锁

#### 表级锁

表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。

##### 表锁

表共享读锁（read lock） 

表独占写锁（write lock）

加了读锁，当前客户端能读，其他客户端也能读。当前客户端不能写，其他客户端写操作会处于阻塞状态。

加了写锁，当前客户端能读能写。其他客户端不能读不能写。



如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，**则其他线程写 t1、读写 t2 的语句都会被阻塞**。**同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。**



##### 元数据锁

MDL锁主要作用是维 护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。**为了避免DML与DDL冲突，保证读写的正确性。** 

![image.png](https://cdn.nlark.com/yuque/0/2024/png/38380929/1729482150525-6908c14a-701b-478b-afee-5eb1e609c484.png?x-oss-process=image%2Fformat%2Cwebp)

不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：

对一张表进行 CRUD 操作时，加的是 MDL 读锁；
对一张表做结构变更操作的时候，加的是 MDL 写锁；



##### 意向锁

如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。

所以，**意向锁的目的是为了快速判断表里是否有记录被加锁。**

为了**避免DML在执行时，加的行锁与表锁的冲突**，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。



**意向共享锁(IS): 由语句select ... lock in share mode添加 。 与 表锁共享锁** 

**(read)兼容，与表锁排他锁(write)互斥。** 

**意向排他锁(IX): 由insert、update、delete、select...for update添加 。与表锁共** 

**享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥。**

一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。

**普通的 select** 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。



##### AUTO-INC 锁

**表里的主键通常都会设置成自增的**，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。
**之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值**，这主要是通过 AUTO-INC 锁实现的。
AUTO-INC 锁是特殊的表锁机制，**锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。**
**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。



#### 行级锁

![image.png](https://cdn.nlark.com/yuque/0/2024/png/38380929/1729505674890-09c0b17c-e4fa-4e8f-b60f-7e55ecca34cf.png?x-oss-process=image%2Fformat%2Cwebp)

Record Lock，记录锁，也就是仅仅把一条记录锁上；
Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；
Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。

##### 记录锁

![image.png](https://cdn.nlark.com/yuque/0/2024/png/38380929/1729509739182-d7b81010-7f26-45c0-802a-d0ade2ebb0ca.png?x-oss-process=image%2Fformat%2Cwebp)

加锁规则和意向锁一样

A. 普通的select语句，执行时，不会加锁。

B. select...lock in share mode，加共享锁，共享锁与共享锁之间兼容。

C. 排它锁与排他锁之间互斥



共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。 

排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他 

锁。



##### 间隙锁

Gap Lock 称为间隙锁，**只存在于可重复读隔离级别**，目的是为了解决可重复读隔离级别下幻读的现象。
假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/%E9%94%81/gap%E9%94%81.drawio.png)



##### 临键锁

Next-Key Lock 称为临键锁，**是 Record Lock + Gap Lock 的组合**，锁定一个范围，并且锁定记录本身。
假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改 id = 5 这条记录。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/%E9%94%81/%E4%B8%B4%E9%94%AE%E9%94%81.drawio.png)

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。**



#### **⾏锁怎么实现的？**

InnoDB **不会直接对数据行加锁**，而是**对访问这行数据所用的索引项加锁**。

如果没有使用索引，InnoDB 就无法精确定位行，只能退而加锁整个表。



#### update 没加索引会锁全表？

**在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。**







#### 🔍 各隔离级别与锁行为解释：

| 隔离级别                         | 行为说明                                                     |
| -------------------------------- | ------------------------------------------------------------ |
| **读未提交（Read Uncommitted）** | 查询时**不加共享锁**，也不等对方释放锁，能读到未提交的数据（脏读） |
| **读提交（Read Committed）**     | 查询时**加共享锁（S 锁）**，**语句执行完立即释放**，防止脏读但**允许不可重复读** |
| **可重复读（Repeatable Read）**  | 查询时也加共享锁，但**直到整个事务提交才释放**，可防止不可重复读，但仍可能幻读（通过 MVCC 和间隙锁处理） |
| **串行化（Serializable）**       | 所有读操作都强制**加锁整行或整段范围（使用间隙锁 + Next-Key Lock）**，确保完全隔离，**阻塞并发**，性能最差但最安全 |

InnoDB 在串行化级别下，会用一种叫 **Next-Key Lock（临键锁）** 的机制来锁定**整个查询范围**，包括：

- **当前已存在的记录（记录锁）**
- **记录之间的间隙（间隙锁）**

这相当于对你的查询条件所涵盖的整个「区间」加锁，确保：

> **别人不能插入、更新或删除你读过的范围内的任何记录。**





#### 串行化级别下的普通查询行为：

- 默认 `SELECT`（也就是快照读）会被**强制变成当前读**。
- 系统会自动为你加锁（**Next-Key Lock**：记录锁 + 间隙锁）。
- **即使只是查数据，也会阻塞别人对这段范围的写操作（插入、更新、删除）**。



#### 死锁

**死锁**：

> 是指两个（或多个）事务在**不同资源上加锁**后，互相等待对方释放资源，导致永远无法继续执行的现象。

##### 🧠 死锁产生的原因：

1. **多个事务交叉加锁**，资源顺序不一致
2. **锁粒度过小**（比如行锁太细），导致锁太多、依赖太多
3. 并发事务处理复杂逻辑时，锁定资源不充分或顺序不统一

------

##### 🛠️ 常见的解决策略：

| 方法                         | 说明                                                    |
| ---------------------------- | ------------------------------------------------------- |
| ✅ **尽量一次性锁定所有资源** | 避免中途再加锁，减少交叉加锁风险                        |
| ✅ **统一锁资源顺序**         | 多个事务**按照同样顺序**访问资源，避免循环依赖          |
| ✅ **适当升级锁粒度**         | 比如使用表锁而不是行锁，减少锁竞争                      |
| ✅ **合理设置超时时间**       | 如 InnoDB 的 `innodb_lock_wait_timeout`，防止长时间等待 |













### 事务

#### 事物的四个特性

▪ 事务：事务是数据库并发控制的基本单位，⼀系列操作必须全部完成，有⼀个失败则全部失败

▪ 原⼦性：事务是不可分割的最小工作单元，一个事务的所有操作要么全部成功，要么全部失败。事务执行过程中出现错误就要回滚到执行前的状态（**undolog实现**）

▪ ⼀致性：事务执行前后都必须处于一致的状态（**原⼦性+持久性+隔离性实现，eg：转账的例⼦**）。是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态

▪ 隔离性：各个事务之间不能被互相⼲扰（**MVCC+锁**）

▪ 持久性：一个事务一旦被提交了，对数据库中数据的改变就是永久的（**redolog实现**）



#### 脏写 脏读 不可重复读 幻读

- 脏写：一个事务修改了未提交事务做的修改。

- 脏读：读到了其他事物未提交的数据。如果另一个事务发生了回滚，读取到的数据就是无效的。

- 不可重复读：一个事务先后读取同一条记录，但两次读取到的数据不同，因为在事务执⾏期间其他事务可能修改了数据。

- 幻读：针对增加、删除。在⼀个事务内多次执行同一条查询语句，如果出现前后两次结果集中的记录数量不⼀样的情况，就

  意味着发⽣了「幻读」现象。



严重程度：脏读>不可重复读>幻读



#### 事务隔离级别

- 读未提交：能够读到没有提交的数据

-  提交读：⼀个事务只能读到其他事物已经提交的数据（每条语句前⽣成⼀个READ VIEW）

- 可重复读：同⼀事务内，任意时刻读到的数据是⼀样的（事务开启前⽣成⼀个READVIEW）

- 串⾏化：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；



![image-20250223172534233](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250223172534233.png)



注：MYSQL在很大程度上避免了幻读（并不是完全）。

**针对快照读（普通 select 语句）**，是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。

**针对当前读（select ... for update 等语句）**，是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。



**举例说明并没有完全解决幻读：**

场景一：

事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。

然后事务 B 插入一条 id = 5 的记录，并且提交了事务。

事务 A 更新 id = 5 这条记录，对没错，事务 A 看不到 id = 5 这条记录，但是他去更新了这条记录，这场景确实很违和，然后再次查询 id = 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景。



场景二：

T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。



本质都是先快照读后当前读，导致发生幻读。

解决办法：要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。



#### 事务隔离级别是如何实现的

对于读未提交，可以读到未提交事务修改的数据，**所以直接读取最新的数据就可以。**

对于串⾏化：**加读写锁**的⽅式来避免并⾏访问

对于读提交和可重复读，通过 Read View 来实现的

「读提交」隔离级别是在**每个 select 都会⽣成⼀个新的 Read View**，也意味着，事务期间的多次读取同⼀条数据，前后两次读的数据可能会出现不⼀致，因为可能这期间另外⼀个事务修改了该记录，并提交了事务。

「可重复读」隔离级别是**启动事务时⽣成⼀个 Read View，然后整个事务期间都在⽤这个 Read View，**这样就保证了在事务期间读到的数据都是事务启动前的记录。



#### 当前读 快照读

- 当前读：读取的是记录的最新版本；读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进⾏加锁

- 当前读通过 next-key 锁(⾏记录锁+间隙锁)；适⽤于 insert，update，delete， select ...for update， select ... lock in share mode 语句

- 快照读：快照读可能读到的并不⼀定是数据的最新版本，⽽有可能是之前的历史版本

- 快照读基于 MVCC 和 undo log 来实现，适⽤于普通select语句



#### 隐藏字段

| 隐藏字段    | 含义                                                         |
| ----------- | ------------------------------------------------------------ |
| DB_TRX_ID   | 最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID。 |
| DB_ROLL_PTR | 回滚指针，指向这条记录的上一个版本，用于配合undo log，指向上一个版本。 |
| DB_ROW_ID   | 隐藏主键，如果表结构没有指定主键，将会生成该隐藏字段。       |

 

#### READVIEW

ReadView（读视图）是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。

| **字段**       | **含义**                                             |
| -------------- | ---------------------------------------------------- |
| m_ids          | 当前活跃的事务ID集合                                 |
| min_trx_id     | 最小活跃事务ID                                       |
| max_trx_id     | 预分配事务ID，当前最大事务ID+1（因为事务ID是自增的） |
| creator_trx_id | ReadView创建者的事务ID                               |



![image-20250224162044914](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250224162044914.png)





#### MVCC



![image-20250224162409549](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250224162409549.png)

**可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。**

**读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。**









### 日志

#### undo log

回滚日志，innodb存储引擎生成的日志，用于记录数据被修改前的信息 , 作用包含两个 : **提供回滚**(保证事务的原子性) 和**MVCC(多版本并发控制)** 。

- 实现事务回滚，保证原子性
- 实现MVCC关键因素之一。MVCC是通过读视图+undo log实现的，undo log维每条记录保存多份历史数据，MYSQL在执行快照读的时候，会根据读视图里面的信息，顺着undo  log版本链找到满足可见性的数据。







#### WAL

Write-Ahead Logging：所有的修改都先被写⼊到⽇志（log）中，然后再写磁盘。如果事务失败，WAL中的记录会被忽略，如果成功，某个时间点写回到数据库⽂件，提交修改。

好处：先写log再写磁盘，随机写变为顺序写，IO次数降低；可以⽤⽇志恢复磁盘数据









#### redo log

重做日志，记录的是事务提交时数据页的**物理修改，是用来实现事务的持久性**。

该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log

file）,前者是在内存中，后者在磁盘中。**当事务提交之后会把所有修改信息都存到该日志文件中**, 用

于在刷新脏页到磁盘,发生错误时, 进行数据恢复使用。



在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在

往磁盘文件中写入数据，由于是日志文件，所以都是顺序写的。**顺序写的效率，要远大于随机写**。 这

种先写日志的方式，称之为 WAL（Write-Ahead Logging）。



- 实现事务持久性
- 随机写变为顺序写  提高性能



#### redo log刷盘时机

- MYSQL正常关闭
- redo log buffer中记录的写入数量大于一般的空间
- innodb后台线程每隔一秒进行刷盘。
- 每次提交事务都将redo log buffer中的redo log 刷盘。（由innodb_db_flush_log_at_trx_commit控制）







#### redo log 和undo log区别













#### binlog

server层生成

二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。



作用：①. 灾难时的数据恢复；②. MySQL的主从复制。

#### binlog刷盘时机

事务执行过程中，先把日志写到binlog cache，事务提交时，再把binlog cache写入到binlog文件中。

![image-20250224175130871](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250224175130871.png)

![image-20250224175220285](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250224175220285.png)





#### binlog和redo log区别

- binlog是server层实现的，redo log是innodb存储引擎实现的

- binlog是追加写，redo log循环写。
- binlog用于主从复制，灾难时的数据恢复，redo log用于掉电时的恢复。
- binlog有三种格式，redo log是物理日志，记录的是在某个数据页做了什么修改。

![image-20250224175816162](C:\Users\wangyupeng\AppData\Roaming\Typora\typora-user-images\image-20250224175816162.png)









#### 一条update语句的执行流程















#### 两阶段提交：

如果没有进⾏两阶段提交的问题：

会造成主从不一致



- prepare阶段：将redo log的状态设置为prepare状态。然后将redolog刷盘。
- commit阶段：将binlog刷盘，接着将redo log的状态设置为commit状态。





### 主从复制









### 分库分表











